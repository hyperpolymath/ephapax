// SPDX-License-Identifier: PMPL-1.0-or-later
// Ephapax Lexer - Self-hosting compiler (written in Ephapax linear mode)
//
// This lexer is written in Ephapax itself, demonstrating the linear type system
// by managing all resources (strings, token lists) explicitly.

// Token types
type TokenKind =
    | TokKeyword   // fn, let, if, etc.
    | TokIdent     // variable/function names
    | TokInt       // integer literals
    | TokFloat     // float literals
    | TokString    // string literals
    | TokOp        // operators: +, -, *, /, ==, etc.
    | TokPunct     // punctuation: (, ), {, }, [, ], :, ,, ;
    | TokArrow     // ->
    | TokLambda    // λ or \
    | TokEof       // end of file
    | TokError     // lexical error

// Token with position information
type Token = {
    kind: TokenKind,
    lexeme: String,     // Linear: must be explicitly dropped
    line: I32,
    col: I32,
}

// Lexer state (linear - single owner)
type Lexer = {
    source: String,     // Linear: source code (owned)
    pos: I32,          // Current position in source
    line: I32,         // Current line number
    col: I32,          // Current column number
}

// Keywords mapping
fn is_keyword(word: String): TokenKind =
    if word == "fn" then TokKeyword
    else if word == "let" then TokKeyword
    else if word == "let!" then TokKeyword
    else if word == "drop" then TokKeyword
    else if word == "if" then TokKeyword
    else if word == "then" then TokKeyword
    else if word == "else" then TokKeyword
    else if word == "case" then TokKeyword
    else if word == "of" then TokKeyword
    else if word == "in" then TokKeyword
    else if word == "region" then TokKeyword
    else if word == "with" then TokKeyword
    else if word == "type" then TokKeyword
    else if word == "import" then TokKeyword
    else if word == "as" then TokKeyword
    else if word == "module" then TokKeyword
    else if word == "export" then TokKeyword
    else TokIdent

// Character classification
fn is_whitespace(c: I32): Bool =
    c == 32 || c == 9 || c == 10 || c == 13  // space, tab, LF, CR

fn is_alpha(c: I32): Bool =
    (c >= 65 && c <= 90) || (c >= 97 && c <= 122)  // A-Z, a-z

fn is_digit(c: I32): Bool =
    c >= 48 && c <= 57  // 0-9

fn is_alphanumeric(c: I32): Bool =
    is_alpha(c) || is_digit(c) || c == 95  // includes underscore

// Get character at position (returns -1 if out of bounds)
fn char_at(source: String, pos: I32): I32 =
    if pos < string_len(source) then
        string_char_code(source, pos)
    else
        -1

// Peek character without advancing
fn peek_char(lexer: Lexer): I32 =
    char_at(lexer.source, lexer.pos)

// Advance position by one character
fn advance(lexer: Lexer): Lexer =
    let c = peek_char(lexer) in
    if c == 10 then  // newline
        { source: lexer.source
        , pos: lexer.pos + 1
        , line: lexer.line + 1
        , col: 1
        }
    else
        { source: lexer.source
        , pos: lexer.pos + 1
        , line: lexer.line
        , col: lexer.col + 1
        }

// Skip whitespace
fn skip_whitespace(lexer: Lexer): Lexer =
    let c = peek_char(lexer) in
    if c == -1 then
        lexer
    else if is_whitespace(c) then
        skip_whitespace(advance(lexer))
    else
        lexer

// Skip line comment (// ...)
fn skip_line_comment(lexer: Lexer): Lexer =
    let c = peek_char(lexer) in
    if c == -1 || c == 10 then  // EOF or newline
        lexer
    else
        skip_line_comment(advance(lexer))

// Skip block comment (/* ... */)
fn skip_block_comment(lexer: Lexer, depth: I32): Lexer =
    if depth == 0 then
        lexer
    else
        let c1 = peek_char(lexer) in
        if c1 == -1 then
            lexer  // EOF in comment - error, but return
        else
            let lexer2 = advance(lexer) in
            let c2 = peek_char(lexer2) in
            if c1 == 47 && c2 == 42 then  // /*
                skip_block_comment(advance(lexer2), depth + 1)
            else if c1 == 42 && c2 == 47 then  // */
                skip_block_comment(advance(lexer2), depth - 1)
            else
                skip_block_comment(lexer2, depth)

// Lex identifier or keyword
fn lex_ident(lexer: Lexer, start_pos: I32, start_line: I32, start_col: I32): (Token, Lexer) =
    let c = peek_char(lexer) in
    if c == -1 || !is_alphanumeric(c) then
        // End of identifier
        let len = lexer.pos - start_pos in
        let lexeme = string_substr(lexer.source, start_pos, len) in
        let kind = is_keyword(lexeme) in
        let tok = { kind: kind
                  , lexeme: lexeme
                  , line: start_line
                  , col: start_col
                  } in
        (tok, lexer)
    else
        lex_ident(advance(lexer), start_pos, start_line, start_col)

// Lex integer or float literal
fn lex_number(lexer: Lexer, start_pos: I32, start_line: I32, start_col: I32, has_dot: Bool): (Token, Lexer) =
    let c = peek_char(lexer) in
    if c == -1 then
        // End of number
        let len = lexer.pos - start_pos in
        let lexeme = string_substr(lexer.source, start_pos, len) in
        let kind = if has_dot then TokFloat else TokInt in
        let tok = { kind: kind
                  , lexeme: lexeme
                  , line: start_line
                  , col: start_col
                  } in
        (tok, lexer)
    else if is_digit(c) then
        lex_number(advance(lexer), start_pos, start_line, start_col, has_dot)
    else if c == 46 && !has_dot then  // dot (.)
        lex_number(advance(lexer), start_pos, start_line, start_col, true)
    else
        // End of number
        let len = lexer.pos - start_pos in
        let lexeme = string_substr(lexer.source, start_pos, len) in
        let kind = if has_dot then TokFloat else TokInt in
        let tok = { kind: kind
                  , lexeme: lexeme
                  , line: start_line
                  , col: start_col
                  } in
        (tok, lexer)

// Lex string literal
fn lex_string(lexer: Lexer, start_pos: I32, start_line: I32, start_col: I32): (Token, Lexer) =
    let c = peek_char(lexer) in
    if c == -1 then
        // EOF in string - error
        let tok = { kind: TokError
                  , lexeme: "unterminated string"
                  , line: start_line
                  , col: start_col
                  } in
        (tok, lexer)
    else if c == 34 then  // closing quote (")
        // End of string
        let lexer2 = advance(lexer) in
        let len = lexer2.pos - start_pos in
        let lexeme = string_substr(lexer2.source, start_pos, len) in
        let tok = { kind: TokString
                  , lexeme: lexeme
                  , line: start_line
                  , col: start_col
                  } in
        (tok, lexer2)
    else if c == 92 then  // backslash (escape)
        let lexer2 = advance(lexer) in
        lex_string(advance(lexer2), start_pos, start_line, start_col)
    else
        lex_string(advance(lexer), start_pos, start_line, start_col)

// Lex single token
fn lex_token(lexer: Lexer): (Token, Lexer) =
    // Skip whitespace and comments
    let lexer = skip_whitespace(lexer) in
    let c = peek_char(lexer) in

    if c == -1 then
        // EOF
        let tok = { kind: TokEof
                  , lexeme: ""
                  , line: lexer.line
                  , col: lexer.col
                  } in
        (tok, lexer)

    else if c == 47 then  // slash (/)
        let lexer2 = advance(lexer) in
        let c2 = peek_char(lexer2) in
        if c2 == 47 then  // line comment
            let lexer3 = skip_line_comment(advance(lexer2)) in
            lex_token(lexer3)
        else if c2 == 42 then  // block comment
            let lexer3 = skip_block_comment(advance(lexer2), 1) in
            lex_token(lexer3)
        else
            // Division operator
            let tok = { kind: TokOp
                      , lexeme: "/"
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, lexer2)

    else if is_alpha(c) || c == 95 then  // identifier or keyword
        lex_ident(lexer, lexer.pos, lexer.line, lexer.col)

    else if is_digit(c) then  // number literal
        lex_number(lexer, lexer.pos, lexer.line, lexer.col, false)

    else if c == 34 then  // string literal (")
        let lexer2 = advance(lexer) in
        lex_string(lexer2, lexer.pos, lexer.line, lexer.col)

    else if c == 45 then  // dash (-)
        let lexer2 = advance(lexer) in
        let c2 = peek_char(lexer2) in
        if c2 == 62 then  // arrow (->)
            let tok = { kind: TokArrow
                      , lexeme: "->"
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, advance(lexer2))
        else
            // Minus operator
            let tok = { kind: TokOp
                      , lexeme: "-"
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, lexer2)

    else if c == 92 || c == 955 then  // lambda (\ or λ)
        let lexer2 = advance(lexer) in
        let tok = { kind: TokLambda
                  , lexeme: if c == 92 then "\\" else "λ"
                  , line: lexer.line
                  , col: lexer.col
                  } in
        (tok, lexer2)

    else if c == 61 then  // equals (=)
        let lexer2 = advance(lexer) in
        let c2 = peek_char(lexer2) in
        if c2 == 61 then  // equality (==)
            let tok = { kind: TokOp
                      , lexeme: "=="
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, advance(lexer2))
        else
            // Assignment/equals
            let tok = { kind: TokOp
                      , lexeme: "="
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, lexer2)

    else if c == 33 then  // exclamation (!)
        let lexer2 = advance(lexer) in
        let c2 = peek_char(lexer2) in
        if c2 == 61 then  // not equals (!=)
            let tok = { kind: TokOp
                      , lexeme: "!="
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, advance(lexer2))
        else
            // Bang (for let!)
            let tok = { kind: TokOp
                      , lexeme: "!"
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, lexer2)

    else if c == 60 then  // less than (<)
        let lexer2 = advance(lexer) in
        let c2 = peek_char(lexer2) in
        if c2 == 61 then  // less than or equal (<=)
            let tok = { kind: TokOp
                      , lexeme: "<="
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, advance(lexer2))
        else
            let tok = { kind: TokOp
                      , lexeme: "<"
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, lexer2)

    else if c == 62 then  // greater than (>)
        let lexer2 = advance(lexer) in
        let c2 = peek_char(lexer2) in
        if c2 == 61 then  // greater than or equal (>=)
            let tok = { kind: TokOp
                      , lexeme: ">="
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, advance(lexer2))
        else
            let tok = { kind: TokOp
                      , lexeme: ">"
                      , line: lexer.line
                      , col: lexer.col
                      } in
            (tok, lexer2)

    // Single-character operators and punctuation
    else if c == 43 || c == 42 || c == 37 then  // +, *, %
        let lexer2 = advance(lexer) in
        let tok = { kind: TokOp
                  , lexeme: string_from_char(c)
                  , line: lexer.line
                  , col: lexer.col
                  } in
        (tok, lexer2)

    else if c == 40 || c == 41 || c == 123 || c == 125 || c == 91 || c == 93 then  // ( ) { } [ ]
        let lexer2 = advance(lexer) in
        let tok = { kind: TokPunct
                  , lexeme: string_from_char(c)
                  , line: lexer.line
                  , col: lexer.col
                  } in
        (tok, lexer2)

    else if c == 58 || c == 44 || c == 59 then  // : , ;
        let lexer2 = advance(lexer) in
        let tok = { kind: TokPunct
                  , lexeme: string_from_char(c)
                  , line: lexer.line
                  , col: lexer.col
                  } in
        (tok, lexer2)

    else
        // Unknown character - error
        let lexer2 = advance(lexer) in
        let tok = { kind: TokError
                  , lexeme: string_from_char(c)
                  , line: lexer.line
                  , col: lexer.col
                  } in
        (tok, lexer2)

// Tokenize entire source (returns list of tokens)
fn tokenize(source: String): [Token] =
    let lexer = { source: source
                , pos: 0
                , line: 1
                , col: 1
                } in
    tokenize_loop(lexer, [])

fn tokenize_loop(lexer: Lexer, tokens: [Token]): [Token] =
    let (tok, lexer2) = lex_token(lexer) in
    if tok.kind == TokEof then
        // Append EOF and return
        append(tokens, tok)
    else
        // Append token and continue
        tokenize_loop(lexer2, append(tokens, tok))

// Main entry point
fn main(): I32 =
    let source = "fn add(x: I32, y: I32): I32 = x + y" in
    let tokens = tokenize(source) in
    print_tokens(tokens)

fn print_tokens(tokens: [Token]): I32 =
    // TODO: Implement token printing
    0
